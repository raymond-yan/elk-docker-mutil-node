# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  beats {
  port => 5044
  }
}

filter {
  # Parse arbitrary text and structure it.
  # 通常用于处理没有结构化的log信息，例如 syslog、apache log、mysql log等。
  # 参考 https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html
  grok {
    match => {
      "message" => '%{IPORHOST:clientip} %{USER:ident} %{USER:auth} \[%{HTTPDATE:timestamp}\] "%{WORD:method} %{DATA:request} HTTP/%{NUMBER:httpversion}" %{NUMBER:response:int} (?:-|%{NUMBER:bytes:int}) %{QS:referer} %{QS:useragent}'
    }
  }

  # 时间转换插件
  date {
    match => [ "timestamp", "dd/MMM/YYYY:HH:mm:ss Z"]
    locale => en
  }
  
  # 将ip地址转换为 geo 地址
  geoip {
    source => "clientip"
  }

  useragent {
    source => 'useragent'
    target => 'useragent_parse'
  }
}

output {

  stdout {
    codec => dots {}
  }

  elasticsearch {
    hosts => ["http://es01:9200","http://es02:9200","http://es03:9200"]
    index => "logstash-apache-log"
    # index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
    #user => "elastic"
    #password => "changeme"
  }
}